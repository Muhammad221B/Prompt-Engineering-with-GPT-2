{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a8fbfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a84d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Direct Prompt ---\n",
      "Output 1:\n",
      "Write a motivational quote about overcoming fear.\n",
      "\n",
      "\"It's an amazing feeling when you're feeling scared, because your brain feels the pressure, and it's hard to do anything about it. But I think it's the most comforting thing about it\n",
      "\n",
      "Output 2:\n",
      "Write a motivational quote about overcoming fear.\n",
      "\n",
      "7. Don't just read the book.\n",
      "\n",
      "I don't have any great ideas for how to build a list of my favorite books, but I do know that I've written some great ones\n",
      "\n",
      "Output 3:\n",
      "Write a motivational quote about overcoming fear.\n",
      "\n",
      "Step 6: Write a motivational quote about overcoming fear.\n",
      "\n",
      "Step 7: Write a motivational quote about overcoming fear.\n",
      "\n",
      "Step 8: Write a motivational quote about overcoming fear.\n",
      "\n",
      "Step\n",
      "\n",
      "\n",
      "--- Scenario Prompt ---\n",
      "Output 1:\n",
      "Imagine you're helping a friend who failed a test. Write something encouraging.\n",
      "\n",
      "I'm trying to read you the book in English, but I can't. You're my friend. I want you to get involved.\n",
      "\n",
      "You're reading\n",
      "\n",
      "Output 2:\n",
      "Imagine you're helping a friend who failed a test. Write something encouraging.\n",
      "\n",
      "When you're writing something, you need to write it. When you're writing something, you need to write it.\n",
      "\n",
      "The more you write it, the\n",
      "\n",
      "Output 3:\n",
      "Imagine you're helping a friend who failed a test. Write something encouraging. This can help you feel better about yourself, your work, and your achievements.\n",
      "\n",
      "Write something encouraging. This can help you feel better about yourself, your work, and\n",
      "\n",
      "\n",
      "--- Persona Prompt ---\n",
      "Output 1:\n",
      "As a wise monk, write a quote about inner strength. \"Strength is the only way to achieve peace and tranquility, to gain a certain quality of life, and to live in peace. It is the only way to give up all that you\n",
      "\n",
      "Output 2:\n",
      "As a wise monk, write a quote about inner strength.\n",
      "\n",
      "When you have the power, you can make your life a living hell.\n",
      "\n",
      "The truth is, if you have a power, you can make your life a hell.\n",
      "\n",
      "\n",
      "Output 3:\n",
      "As a wise monk, write a quote about inner strength. Then try to use it in your training.\n",
      "\n",
      "5. Use the word \"expertise\" to describe your spiritual practice.\n",
      "\n",
      "You may have heard of the phrase \"pract\n",
      "\n",
      "\n",
      "--- Keyword Prompt ---\n",
      "Output 1:\n",
      "Using the words 'growth', 'struggle', and 'hope', write something inspiring. This is a good time to start a new project.\n",
      "\n",
      "So, let's look at a typical day.\n",
      "\n",
      "On the first day, I\n",
      "\n",
      "Output 2:\n",
      "Using the words 'growth', 'struggle', and 'hope', write something inspiring. For us, the answer is 'no'. We don't know what we can do, but we know that we can do it.\n",
      "\n",
      "This post\n",
      "\n",
      "Output 3:\n",
      "Using the words 'growth', 'struggle', and 'hope', write something inspiring.\n",
      "\n",
      "In the next sentence, write a short essay about how you've been fortunate enough to have been raised in a supportive, supportive family.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--- Conversational Prompt ---\n",
      "Output 1:\n",
      "User: I feel like giving up. GPT-2: Here's a quote for you: \"A lot of people have been like, 'I'm not going to do this anymore, and I'm not going to do this anymore.' I\n",
      "\n",
      "Output 2:\n",
      "User: I feel like giving up. GPT-2: Here's a quote for you: \"The game is dead.\"\n",
      "\n",
      "PlayStation 3: Yeah, it's dead.\n",
      "\n",
      "PlayStation Vita: You don't like it?\n",
      "\n",
      "Output 3:\n",
      "User: I feel like giving up. GPT-2: Here's a quote for you: \"I have been looking forward to this game for a long time. I was very excited to see it when I got the chance to play it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt, max_length=50, num_return_sequences=3):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "\n",
    "prompts = {\n",
    "    \"Direct\": \"Write a motivational quote about overcoming fear.\",\n",
    "    \"Scenario\": \"Imagine you're helping a friend who failed a test. Write something encouraging.\",\n",
    "    \"Persona\": \"As a wise monk, write a quote about inner strength.\",\n",
    "    \"Keyword\": \"Using the words 'growth', 'struggle', and 'hope', write something inspiring.\",\n",
    "    \"Conversational\": \"User: I feel like giving up. GPT-2: Here's a quote for you:\"\n",
    "}\n",
    "\n",
    "all_outputs = {}\n",
    "for prompt_type, prompt_text in prompts.items():\n",
    "    print(f\"\\n--- {prompt_type} Prompt ---\")\n",
    "    outputs = generate_text(prompt_text)\n",
    "    all_outputs[prompt_type] = outputs\n",
    "    for i, out in enumerate(outputs, 1):\n",
    "        print(f\"Output {i}:\\n{out}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5883bd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## from: His Last Bow (Sherlock Holmes) by Arthur Conan Doyle\n",
    "human_reference = \"Education never ends, Watson. It is a series of lessons, with the greatest for the last.\"\n",
    "## reference_url : \"https://www.goodreads.com/quotes/349646-education-never-ends-watson-it-is-a-series-of-lessons\" ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06909a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--roberta-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 52.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.86 seconds, 8.06 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Prompt Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Output #",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "BERTScore F1",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "48fc6359-201c-470a-aa4e-d37c65936bf5",
       "rows": [
        [
         "0",
         "Direct",
         "1",
         "0.8419980406761169"
        ],
        [
         "1",
         "Direct",
         "2",
         "0.8330712914466858"
        ],
        [
         "2",
         "Direct",
         "3",
         "0.8284337520599365"
        ],
        [
         "3",
         "Scenario",
         "1",
         "0.8323811888694763"
        ],
        [
         "4",
         "Scenario",
         "2",
         "0.8338097929954529"
        ],
        [
         "5",
         "Scenario",
         "3",
         "0.8295992612838745"
        ],
        [
         "6",
         "Persona",
         "1",
         "0.8345548510551453"
        ],
        [
         "7",
         "Persona",
         "2",
         "0.8432801365852356"
        ],
        [
         "8",
         "Persona",
         "3",
         "0.8337143063545227"
        ],
        [
         "9",
         "Keyword",
         "1",
         "0.8371113538742065"
        ],
        [
         "10",
         "Keyword",
         "2",
         "0.8331712484359741"
        ],
        [
         "11",
         "Keyword",
         "3",
         "0.8285697102546692"
        ],
        [
         "12",
         "Conversational",
         "1",
         "0.828680157661438"
        ],
        [
         "13",
         "Conversational",
         "2",
         "0.830352246761322"
        ],
        [
         "14",
         "Conversational",
         "3",
         "0.8396840691566467"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 15
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt Type</th>\n",
       "      <th>Output #</th>\n",
       "      <th>BERTScore F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0.841998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Direct</td>\n",
       "      <td>2</td>\n",
       "      <td>0.833071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Direct</td>\n",
       "      <td>3</td>\n",
       "      <td>0.828434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scenario</td>\n",
       "      <td>1</td>\n",
       "      <td>0.832381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scenario</td>\n",
       "      <td>2</td>\n",
       "      <td>0.833810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Scenario</td>\n",
       "      <td>3</td>\n",
       "      <td>0.829599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Persona</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Persona</td>\n",
       "      <td>2</td>\n",
       "      <td>0.843280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Persona</td>\n",
       "      <td>3</td>\n",
       "      <td>0.833714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Keyword</td>\n",
       "      <td>1</td>\n",
       "      <td>0.837111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Keyword</td>\n",
       "      <td>2</td>\n",
       "      <td>0.833171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Keyword</td>\n",
       "      <td>3</td>\n",
       "      <td>0.828570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Conversational</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Conversational</td>\n",
       "      <td>2</td>\n",
       "      <td>0.830352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Conversational</td>\n",
       "      <td>3</td>\n",
       "      <td>0.839684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prompt Type  Output #  BERTScore F1\n",
       "0           Direct         1      0.841998\n",
       "1           Direct         2      0.833071\n",
       "2           Direct         3      0.828434\n",
       "3         Scenario         1      0.832381\n",
       "4         Scenario         2      0.833810\n",
       "5         Scenario         3      0.829599\n",
       "6          Persona         1      0.834555\n",
       "7          Persona         2      0.843280\n",
       "8          Persona         3      0.833714\n",
       "9          Keyword         1      0.837111\n",
       "10         Keyword         2      0.833171\n",
       "11         Keyword         3      0.828570\n",
       "12  Conversational         1      0.828680\n",
       "13  Conversational         2      0.830352\n",
       "14  Conversational         3      0.839684"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "generated_texts = []\n",
    "prompt_labels = []\n",
    "\n",
    "for prompt_type, outputs in all_outputs.items():\n",
    "    for i, text in enumerate(outputs, 1):\n",
    "        generated_texts.append(text)\n",
    "        prompt_labels.append((prompt_type, i))\n",
    "\n",
    "P, R, F1 = score(generated_texts, [human_reference]*len(generated_texts), lang=\"en\", verbose=True)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Prompt Type\": [label[0] for label in prompt_labels],\n",
    "    \"Output\": [label[1] for label in prompt_labels],\n",
    "    \"BERTScore F1\": F1.tolist()\n",
    "})\n",
    "\n",
    "results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
